{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd  \n",
    "import requests                                                                     # Importing packages from my Python venv \n",
    "from bs4 import BeautifulSoup \n",
    "import sqlite3\n",
    "import locale\n",
    "import altair as alt\n",
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_url = 'http://en.wikipedia.org/wiki/List_of_S%26P_500_companies'              # Assigning link to 'sp500_url'\n",
    "response = requests.get(sp500_url)                                                  # Using request to get access to 'sp500_url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code ==200:\n",
    "    print('Request successful')\n",
    "else:                                                                              # Checking status = 200 code using 'if' & 'else'\n",
    "    print('Request not successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find ('table')                                       # Using Beautifulsoup() to find table within my url in 'response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_html(str(table))[0]            # Using pandas to read link from table and assigning a value to a variable 'data_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting DataFrame:\")\n",
    "\n",
    "print(data_table.head(503))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = data_table ['Symbol'].tolist()                                                              # Assigning 'tickers' to only the 'Symbol' of the 'data_table' and convert into a list()\n",
    "tickers_list = [ticker.replace('BF.B', 'BF-B').replace('BRK.B', 'BRK-B') for ticker in tickers]       # Replacing two incorrect Value 'tickers' within a variable 'tickers_list'\n",
    "\n",
    "print('Tickers list')\n",
    "print(tickers_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_list = data_table ['GICS Sector'].tolist()       # Convert 'GICS Sector' into a list() within 'data_table' assigned to 'sectors_list'\n",
    "\n",
    "print('Sectors list')\n",
    "print(sectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_list = data_table ['Security'].tolist()         # Convert 'Security' into a list() within 'data_table' assigned to 'stocks_list'\n",
    "\n",
    "print('Stocks list')\n",
    "print(stocks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry_list = data_table ['GICS Sub-Industry'].tolist()                     # Convert 'GICS Sub-Industry' into a list() within 'data_table' assigned to 'Industry_list'\n",
    "\n",
    "print('Industry list')\n",
    "print(Industry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_list = data_table ['Headquarters Location'].tolist()                                  # Convert 'Headquarters Location' into a list() within 'data_table' assigned to 'Location_list'\n",
    "\n",
    "print('Headquarters Location list')\n",
    "print(Location_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sp500_data_table_columns = pd.DataFrame({\n",
    "    'Tickers': tickers_list,\n",
    "    'Stocks': stocks_list,                                                  # Adding my variables ('tickers_list','stocks_list, and 'sectors_list') to a new Dataframe 'Sp500_columns' using pandas & {}\n",
    "    'Sectors': sectors_list,\n",
    "    'Industry': Industry_list,\n",
    "    'Location': Location_list,}) \n",
    "\n",
    "print(Sp500_data_table_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data From Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_volume = yf.download(tickers_list, period=\"1y\", interval=\"1d\")[['Volume']]    # Using 'yf' to download all the info in the 'tickers_list' between those dates and assigning it to 'tickers_price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate The Volume For Each Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_volume = tickers_volume['Volume'].resample('D').sum()                                                # Calculate the daily volume for each ticker\n",
    "\n",
    "weekly_average_volume = tickers_volume['Volume'].resample('W').mean()                               # Calculate the daily average volume for each ticker\n",
    "\n",
    "yearly_average_volume = tickers_volume['Volume'].resample('Y').mean()                               # Calculate the yearly average volume for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Daily Volume for Each Ticker:\")\n",
    "\n",
    "daily_volume.sort_values(by='Date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weekly Average Volume for Each Ticker:\")\n",
    "\n",
    "weekly_average_volume.sort_values(by='Date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nYearly Average Volume for Each Ticker:\")\n",
    "\n",
    "print(yearly_average_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap_url = 'https://www.liberatedstocktrader.com/sp-500-companies/'            \n",
    "response_2 = requests.get(market_cap_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_2.status_code == 200 :\n",
    " print('Request successful')                                                                        # Checking status = 200 code using 'if' & 'else'\n",
    "else: print('Request not successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_2 = BeautifulSoup(response_2.content, 'html.parser')                                        # Using Beautifulsoup() to find table within my url in 'response_2'\n",
    "market_table = soup_2.find_all ('table')                                                         # Using 'find_all' to read all the tables on the web\n",
    "Sp500_columns = pd.read_html(str(market_table[0]))[0]                                            # Using pd() to read the first table on the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Market Cap) & Function Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sp500_columns.iloc[0] = ['Tickers', 'Names', 'Sectors', 'Market Cap']                                                   # Assigns names to the columns of the DataFrame.\n",
    "\n",
    "def format_market_cap(market_cap):                                                                                      # Defines a function to format market cap values.\n",
    "        try:\n",
    "            market_cap = float(market_cap.replace('$', '').replace('B', 'e9').replace('M', 'e6').replace('T', 'e12'))   # Converts the market cap value to a floating-point number.\n",
    "            if market_cap >= 1e12:\n",
    "                return \"${:.2f} T\".format(market_cap / 1e12)                                                            # The function then checks the magnitude of the market cap and appends 'T', 'B', or 'M' accordingly.\n",
    "            elif market_cap >= 1e9:\n",
    "                return \"${:.2f} B\".format(market_cap / 1e9)\n",
    "            else:\n",
    "                return \"${:.2f} M\".format(market_cap / 1e6)\n",
    "            \n",
    "        except ValueError:\n",
    "            return market_cap\n",
    "\n",
    "Sp500_columns[3] = Sp500_columns[3].apply(format_market_cap)     \n",
    "\n",
    "print(\"Resulting DataFrame:\")\n",
    "print(Sp500_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Merging (JOIN) Drop and Rename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_Sp500_columns = pd.merge(Sp500_data_table_columns, Sp500_columns[[0,3]], left_on='Tickers', right_on=0, how='left')             # pd.merge is used to merge two DataFrames 'JOIN'\n",
    "\n",
    "Merged_Sp500_columns.drop(0, axis=1, inplace=True)                                                                                     # Dropping Unnecessary Columns in merged DataFrames\n",
    "Merged_Sp500_columns.drop('Location', axis=1, inplace=True)\n",
    "Merged_Sp500_columns.drop('Industry', axis=1, inplace=True)\n",
    "\n",
    "Merged_Sp500_columns.rename(columns={ 3: 'Market_Cap'}, inplace=True)                                                                   # Renaming Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mapping Updates Columns within DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap_mapping = {\n",
    "    'ABNB': '$85.698B',\n",
    "    'BRK-B': '$773.209B',                                                                                                   # 'Mapping' keys are tickers, and values are the corresponding market cap values \n",
    "    'BX': '$139.435B',\n",
    "    'BF-B': '$29.172B',\n",
    "    'COR': '$40.92B',\n",
    "    'HUBB': '$16.077B',\n",
    "    'KVUE': '$38.623B',\n",
    "    'LULU': '$57.82B',\n",
    "    'VLTO': '$18.609B'}\n",
    "\n",
    "for ticker, market_cap_value in market_cap_mapping.items():                                                                 \n",
    "    Merged_Sp500_columns.loc[Merged_Sp500_columns['Tickers'] == ticker, 'Market_Cap'] = market_cap_value                     # Locates rows in the DataFrame  where 'Tickers' match the current `ticker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_average(ticker):                                                                               # Defines a function to calculate the Daily Volume\n",
    "    ticker_monthly_data = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "   monthly_average = ticker_monthly_data['Volume'].resample('M').mean()                                                # Calculates the mean of the Daily Volume for each ticker\n",
    "    return monthly_average.mean()  \n",
    "\n",
    "Merged_Sp500_columns['Average_Monthly_Volume'] = Merged_Sp500_columns['Tickers'].apply(calculate_monthly_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weekly_average(ticker):                                                                               # Defines a function to calculate the weekly average\n",
    "    ticker_data = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "    weekly_average = ticker_data['Volume'].resample('W').mean()                                                     # Calculates the mean of the weekly average volumes for each ticker\n",
    "    return weekly_average.mean()  \n",
    "\n",
    "Merged_Sp500_columns['Average_Weekly_Volume'] = Merged_Sp500_columns['Tickers'].apply(calculate_weekly_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Volume) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Daily Volume' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Merged_Sp500_columns['Average_Monthly_Volume'] = Merged_Sp500_columns['Average_Monthly_Volume'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Weekly Average Volume' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Merged_Sp500_columns['Average_Weekly_Volume'] = Merged_Sp500_columns['Average_Weekly_Volume'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Tickers                 503 non-null    object\n",
      " 1   Stocks                  503 non-null    object\n",
      " 2   Sectors                 503 non-null    object\n",
      " 3   Market_Cap              503 non-null    object\n",
      " 4   Average_Monthly_Volume  503 non-null    int64 \n",
      " 5   Average_Weekly_Volume   503 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 23.7+ KB\n"
     ]
    }
   ],
   "source": [
    "Merged_Sp500_columns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting S&P 500 DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Sectors</th>\n",
       "      <th>Market_Cap</th>\n",
       "      <th>Average_Monthly_Volume</th>\n",
       "      <th>Average_Weekly_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>$55.20 B</td>\n",
       "      <td>3521469</td>\n",
       "      <td>3526526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>$10.37 B</td>\n",
       "      <td>1045112</td>\n",
       "      <td>1046008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AES</td>\n",
       "      <td>AES Corporation</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>$12.06 B</td>\n",
       "      <td>5908709</td>\n",
       "      <td>5925824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>APA</td>\n",
       "      <td>APA Corporation</td>\n",
       "      <td>Energy</td>\n",
       "      <td>$13.59 B</td>\n",
       "      <td>5000462</td>\n",
       "      <td>5095130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>T</td>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>$100.44 B</td>\n",
       "      <td>38979177</td>\n",
       "      <td>38228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$13.96 B</td>\n",
       "      <td>394655</td>\n",
       "      <td>403305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$24.90 B</td>\n",
       "      <td>1495374</td>\n",
       "      <td>1511213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation</td>\n",
       "      <td>Financials</td>\n",
       "      <td>$5.15 B</td>\n",
       "      <td>3659809</td>\n",
       "      <td>3750224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$83.58 B</td>\n",
       "      <td>1925033</td>\n",
       "      <td>1972249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>EBAY</td>\n",
       "      <td>eBay</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>$22.88 B</td>\n",
       "      <td>5245734</td>\n",
       "      <td>5214642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tickers                Stocks                 Sectors Market_Cap  \\\n",
       "0       MMM                    3M             Industrials   $55.20 B   \n",
       "1       AOS           A. O. Smith             Industrials   $10.37 B   \n",
       "7       AES       AES Corporation               Utilities   $12.06 B   \n",
       "39      APA       APA Corporation                  Energy   $13.59 B   \n",
       "48        T                  AT&T  Communication Services  $100.44 B   \n",
       "..      ...                   ...                     ...        ...   \n",
       "499    ZBRA    Zebra Technologies  Information Technology   $13.96 B   \n",
       "500     ZBH         Zimmer Biomet             Health Care   $24.90 B   \n",
       "501    ZION  Zions Bancorporation              Financials    $5.15 B   \n",
       "502     ZTS                Zoetis             Health Care   $83.58 B   \n",
       "162    EBAY                  eBay  Consumer Discretionary   $22.88 B   \n",
       "\n",
       "     Average_Monthly_Volume  Average_Weekly_Volume  \n",
       "0                   3521469                3526526  \n",
       "1                   1045112                1046008  \n",
       "7                   5908709                5925824  \n",
       "39                  5000462                5095130  \n",
       "48                 38979177               38228193  \n",
       "..                      ...                    ...  \n",
       "499                  394655                 403305  \n",
       "500                 1495374                1511213  \n",
       "501                 3659809                3750224  \n",
       "502                 1925033                1972249  \n",
       "162                 5245734                5214642  \n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Resulting S&P 500 DataFrame:\")\n",
    "\n",
    "Merged_Sp500_columns.sort_values(by='Stocks',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame to SQLite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('SP500_Database.db')  \n",
    "\n",
    "Merged_Sp500_columns.to_sql('SP500_Columns_VL', conn, index=False, if_exists='replace')\n",
    "\n",
    "conn.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_Sp500_columns.to_excel('SP500_excel_file.xlsx', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
