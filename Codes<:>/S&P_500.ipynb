{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Liberties  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd  \n",
    "import requests                                                                     # Importing packages from my Python venv \n",
    "from bs4 import BeautifulSoup \n",
    "import sqlite3\n",
    "import locale\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_url = 'http://en.wikipedia.org/wiki/List_of_S%26P_500_companies'              # Assigning link to 'sp500_url'\n",
    "response = requests.get(sp500_url)                                                  # Using request to get access to 'sp500_url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code ==200:\n",
    "    print('Request successful')\n",
    "else:                                                                              # Checking status = 200 code using 'if' & 'else'\n",
    "    print('Request not successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find ('table')                                       # Using Beautifulsoup() to find table within my url in 'response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_html(str(table))[0]            # Using pandas to read link from table and assigning a value to a variable 'data_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting DataFrame:\")\n",
    "\n",
    "print(data_table.head(503))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = data_table ['Symbol'].tolist()                                                              # Assigning 'tickers' to only the 'Symbol' of the 'data_table' and convert into a list()\n",
    "tickers_list = [ticker.replace('BF.B', 'BF-B').replace('BRK.B', 'BRK-B') for ticker in tickers]       # Replacing two incorrect Value 'tickers' within a variable 'tickers_list'\n",
    "\n",
    "print('Tickers list')\n",
    "print(tickers_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_list = data_table ['GICS Sector'].tolist()       # Convert 'GICS Sector' into a list() within 'data_table' assigned to 'sectors_list'\n",
    "\n",
    "print('Sectors list')\n",
    "print(sectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = data_table ['Security'].tolist()         # Convert 'Security' into a list() within 'data_table' assigned to 'stocks_list'\n",
    "\n",
    "print('Stocks list')\n",
    "print(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry_list = data_table ['GICS Sub-Industry'].tolist()                     # Convert 'GICS Sub-Industry' into a list() within 'data_table' assigned to 'Industry_list'\n",
    "\n",
    "print('Industry list')\n",
    "print(Industry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_list = data_table ['Headquarters Location'].tolist()                                  # Convert 'Headquarters Location' into a list() within 'data_table' assigned to 'Location_list'\n",
    "\n",
    "print('Headquarters Location list')\n",
    "print(Location_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sp500_columns = pd.DataFrame({\n",
    "    'Ticker': tickers_list,\n",
    "    'Company': company_list,                                                  # Adding my variables ('tickers_list','stocks_list, and 'sectors_list') to a new Dataframe 'Sp500_columns' using pandas & {}\n",
    "    'Sector': sectors_list,\n",
    "    'Industry': Industry_list,\n",
    "    'Location': Location_list,}) \n",
    "\n",
    "print(Sp500_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data From Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_volume = yf.download(tickers_list, period=\"1y\", interval=\"1d\")[['Volume']]    # Using 'yf' to download all the info in the 'tickers_list' between those dates and assigning it to 'tickers_price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate The Volume For Each Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_volume = tickers_volume['Volume'].resample('D').sum()                                                # Calculate the daily volume for each ticker\n",
    "\n",
    "monthly_volume = tickers_volume['Volume'].resample('M').mean()                                           # Calculate the monthly average volume for each ticker\n",
    "\n",
    "weekly_average_volume = tickers_volume['Volume'].resample('W').mean()                               # Calculate the daily average volume for each ticker\n",
    "\n",
    "yearly_average_volume = tickers_volume['Volume'].resample('Y').mean()                               # Calculate the yearly average volume for each ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Market Caps From Each Ticker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for ticker in tickers_list:\n",
    "    try:                                             # Importing Tickers from S&P 500 (thicker_list)              \n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        \n",
    "        \n",
    "                                                     # Extracting information\n",
    "        market_cap = info.get('marketCap', 'N/A')\n",
    "        name =  'N/A'  \n",
    "        sector = 'N/A'  \n",
    "        \n",
    "                                                     # Append the data to the list\n",
    "        data.append({\n",
    "            'Ticker': ticker,\n",
    "            'Company': name,\n",
    "            'Sector': sector,\n",
    "            'Market_Cap': market_cap\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "                                                    # Create a DataFrame from the list of data\n",
    "SP500 = pd.DataFrame(data)\n",
    "\n",
    "SP500_MCS = SP500.sort_values(by='Market_Cap', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_MCS.drop('Company', axis=1, inplace=True)\n",
    "                                                                     # Dropping Unnecessary columns from DataFrame(SP500_MC)\n",
    "SP500_MCS.drop('Sector', axis=1, inplace=True)\n",
    "\n",
    "print(SP500_MCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Market Cap) & Function Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_market_cap(market_cap):\n",
    "    if isinstance(market_cap, (int, float)):\n",
    "                                                                   # If it's already a numeric value, format it accordingly\n",
    "        if market_cap >= 1e12:\n",
    "            return \"${:.2f} T\".format(market_cap / 1e12)\n",
    "        elif market_cap >= 1e9:\n",
    "            return \"${:.2f} B\".format(market_cap / 1e9)\n",
    "        elif market_cap >= 1e6:\n",
    "            return \"${:.2f} M\".format(market_cap / 1e6)\n",
    "        else:\n",
    "            return \"${:.2f}\".format(market_cap)\n",
    "    else:\n",
    "        try:\n",
    "                                                                   # Convert the market cap value to a floating-point number\n",
    "            market_cap = float(market_cap.replace('$', '').replace('B', 'e9').replace('M', 'e6').replace('T', 'e12'))\n",
    "\n",
    "                                                                   # Check the magnitude of the market cap and append 'T', 'B', or 'M' accordingly\n",
    "            if market_cap >= 1e12:\n",
    "                return \"${:.2f} T\".format(market_cap / 1e12)\n",
    "            elif market_cap >= 1e9:\n",
    "                return \"${:.2f} B\".format(market_cap / 1e9)\n",
    "            elif market_cap >= 1e6:\n",
    "                return \"${:.2f} M\".format(market_cap / 1e6)\n",
    "            else:\n",
    "                return \"${:.2f}\".format(market_cap)\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error formatting market cap: {e}\")\n",
    "            return market_cap                                       # Return the original value if there's an issue with formatting\n",
    "\n",
    "\n",
    "SP500_MCS['Market_Cap'] = SP500_MCS['Market_Cap'].apply(format_market_cap)\n",
    "\n",
    "print(SP500_MCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Merging (JOIN) Drop And Inserting Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns = pd.merge(Sp500_columns, SP500_MCS[['Ticker', 'Market_Cap']], left_on='Ticker', right_on='Ticker', how='right')             # pd.merge is used to merge two DataFrames 'JOIN'\n",
    "\n",
    "                                                                                   \n",
    "Updated_Sp500_columns.drop('Industry', axis=1, inplace=True)                                                                                        # Dropping Unnecessary Columns in merged DataFrames\n",
    "\n",
    "\n",
    "Updated_Sp500_columns.insert(0, 'Rank', range(1, len(Updated_Sp500_columns) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function Creation (Date, Open, & Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Date_weekly(ticker):\n",
    "    OC_Date = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "    \n",
    "                                                             # Check if the index is a DatetimeIndex\n",
    "    if not isinstance(OC_Date.index, pd.DatetimeIndex):\n",
    "        raise KeyError(f\"DatetimeIndex not found in {ticker} data.\")\n",
    "\n",
    "                                                            # Resample the data to weekly frequency, considering Friday as the end of the week\n",
    "    Weekly_Date = OC_Date.resample('W-Fri').last()  # Use 'last' to get the last data point for the week\n",
    "    \n",
    "    \n",
    "                                                             # Get the most recent weekly date value\n",
    "    most_recent_weekly_date = Weekly_Date.index[-1]\n",
    "    \n",
    "                                                             # Extract the date part from the string\n",
    "    date_part = most_recent_weekly_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    return date_part\n",
    "\n",
    "Updated_Sp500_columns['Date'] = Updated_Sp500_columns['Ticker'].apply(calculate_Date_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_open_weekly_average(ticker):                                                                               # Defines a function to calculate the Open\n",
    "    Open_Close = yf.download(ticker , period= \"1y\", interval=\"1d\")\n",
    "    Open_SP500 = Open_Close['Open'].resample('W').mean()                                                                 # Calculates the mean of the Open for each ticker\n",
    "                                                                                                                         \n",
    "    most_recent_weekly_open = Open_SP500.iloc[-1]                                                                        # Get the most recent weekly open value\n",
    "    return most_recent_weekly_open \n",
    "\n",
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Ticker'].apply(calculate_open_weekly_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_close_weekly_average(ticker):                                                                               # Defines a function to calculate the Close\n",
    "    Open_Close = yf.download(ticker, period= \"1y\", interval=\"1d\")\n",
    "    Close_SP500 = Open_Close['Close'].resample('W').mean()                                                # Calculates the mean of the Close for each ticker\n",
    "    \n",
    "    most_recent_weekly_close = Close_SP500.iloc[-1]                                                                        # Get the most recent weekly open value\n",
    "    return most_recent_weekly_close  \n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Ticker'].apply(calculate_close_weekly_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Creation Weekly Percentage (Open/Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage change and add the column to the DataFrame\n",
    "Updated_Sp500_columns['Weekly_Percentage'] = (((Updated_Sp500_columns['Weekly_Close'] - Updated_Sp500_columns['Weekly_Open']) / Updated_Sp500_columns['Weekly_Open']) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function Creation (Weekly Volume & Monthly Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weekly_average(ticker):                                                                               # Defines a function to calculate the weekly average\n",
    "    ticker_data = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "    weekly_average = ticker_data['Volume'].resample('W').mean()                                                     # Calculates the mean of the weekly average volumes for each ticker\n",
    "    \n",
    "    most_recent_weekly_volume = weekly_average.iloc[-1]                                                                        # Get the most recent weekly open value\n",
    "    return most_recent_weekly_volume  \n",
    "  \n",
    "\n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Ticker'].apply(calculate_weekly_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_average(ticker):                                                                               # Defines a function to calculate the Daily Volume\n",
    "    ticker_monthly_data = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "    monthly_average = ticker_monthly_data['Volume'].resample('M').mean()                                                # Calculates the mean of the Daily Volume for each ticker\n",
    "    \n",
    "    most_recent_monthly_volume = monthly_average.iloc[-1]                                                                        # Get the most recent weekly open value\n",
    "    return most_recent_monthly_volume    \n",
    "\n",
    "Updated_Sp500_columns['Monthly_Volume'] = Updated_Sp500_columns['Ticker'].apply(calculate_monthly_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Volume & Open/Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Average Weekly Open' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Weekly_Open'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Average Weekly Close' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Weekly_Close'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Weekly Average Volume' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Weekly_Volume'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Daily Volume' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Monthly_Volume'] = Updated_Sp500_columns['Monthly_Volume'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Weekly_Open'].astype(int)                   \n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Weekly_Close'].astype(int)                    # Converting Columns To int()\n",
    " \n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Weekly_Volume'].astype(int)                   \n",
    "\n",
    "Updated_Sp500_columns['Monthly_Volume'] = Updated_Sp500_columns['Monthly_Volume'].astype(int)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reapplying Column (Market Cap) to the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_Cap = Updated_Sp500_columns.pop('Market_Cap')\n",
    "Updated_Sp500_columns['Market_Cap'] = Market_Cap\n",
    "\n",
    "print(\"Resulting S&P 500 DataFrame:\")\n",
    "\n",
    "Updated_Sp500_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame to Tableau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau file path\n",
    "Tableau_path = '/Users/Phases/Desktop/Project XV/Tableau/Tableau_XV.csv'\n",
    "\n",
    "# Save the DataFrame to the CSV file, overwriting if it already exists\n",
    "Updated_Sp500_columns.to_csv(Tableau_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Percentage Sign %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns['Weekly_Percentage'] = (Updated_Sp500_columns['Weekly_Percentage'].astype(float).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns.info()                              # Calling All The Info() Of This DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame To SQLite With Primary Key (Recreation Of Tables)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New database file path\n",
    "project_path = '/Users/Phases/Desktop/Project XV'\n",
    "instance_folder = 'Instance'\n",
    "SP_Database = 'SP500_Database.db'\n",
    "SP500_Database_Path = os.path.join(project_path, instance_folder, SP_Database)\n",
    "\n",
    "# Connect to the SQLite database using the new file path\n",
    "conn = sqlite3.connect(SP500_Database_Path)\n",
    "\n",
    "Updated_Sp500_columns.to_sql('SP500_Columns_Key', conn, index=False, if_exists='replace')   # Adding DataFrame To SQLite Database\n",
    "\n",
    "cursor = conn.cursor()    # Starting SQL Query \n",
    "\n",
    "                          # Creating New Table With Primary Key\n",
    "cursor.execute('''         \n",
    "    CREATE TABLE IF NOT EXISTS SP500_Columns_Key_New (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        Rank INTEGER,\n",
    "        Ticker TEXT,\n",
    "        Company TEXT,\n",
    "        Sector TEXT,\n",
    "        Location TEXT,\n",
    "        Date DATE,\n",
    "        Weekly_Open INTEGER,\n",
    "        Weekly_Close INTEGER,\n",
    "        Weekly_Percentage TEXT,\n",
    "        Weekly_Volume INTEGER,\n",
    "        Monthly_Volume INTEGER,\n",
    "        Market_Cap TEXT\n",
    "    )''')\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                          # Copying Data From Existing Table To The New Table With Primary Key\n",
    "cursor.execute('''\n",
    "    INSERT INTO SP500_Columns_Key_New (Rank, Ticker, Company, Sector, Location, Date, Weekly_Open, Weekly_Close, Weekly_Percentage, Weekly_Volume, Monthly_Volume, Market_Cap)    \n",
    "    SELECT Rank, Ticker, Company, Sector, Location, Date, Weekly_Open, Weekly_Close, Weekly_Percentage, Weekly_Volume, Monthly_Volume, Market_Cap\n",
    "    FROM SP500_Columns_Key\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                         # Renaming Both Tables One With Primary Key and One Without\n",
    "cursor.execute('''\n",
    "    ALTER TABLE SP500_Columns_Key RENAME TO SP500_Columns_Key_Old\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    ALTER TABLE SP500_Columns_Key_New RENAME TO SP500_Columns_Key\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                        # Dropping Old Table \n",
    "cursor.execute('''\n",
    "    DROP TABLE IF EXISTS SP500_Columns_Key_Old\n",
    "''')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/Phases/Desktop/Project XV/Excel'\n",
    "file_name = 'SP500_excel.xlsx'\n",
    "\n",
    "# Get the full path to the Excel file\n",
    "excel_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Make sure the folder exists, create it if not\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to Excel\n",
    "Updated_Sp500_columns.to_excel(excel_file_path, index=False, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
