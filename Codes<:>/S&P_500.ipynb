{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Liberties  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd  \n",
    "import requests                                                                     # Importing packages from my Python venv \n",
    "from bs4 import BeautifulSoup \n",
    "import sqlite3\n",
    "import locale\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_url = 'http://en.wikipedia.org/wiki/List_of_S%26P_500_companies'              # Assigning link to 'sp500_url'\n",
    "response = requests.get(sp500_url)                                                  # Using request to get access to 'sp500_url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code ==200:\n",
    "    print('Request successful')\n",
    "else:                                                                              # Checking status = 200 code using 'if' & 'else'\n",
    "    print('Request not successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find ('table')                                       # Using Beautifulsoup() to find table within my url in 'response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = pd.read_html(str(table))[0]            # Using pandas to read link from table and assigning a value to a variable 'data_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting DataFrame:\")\n",
    "\n",
    "print(data_table.head(503))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = data_table ['Symbol'].tolist()                                                              # Assigning 'tickers' to only the 'Symbol' of the 'data_table' and convert into a list()\n",
    "tickers_list = [ticker.replace('BF.B', 'BF-B').replace('BRK.B', 'BRK-B') for ticker in tickers]       # Replacing two incorrect Value 'tickers' within a variable 'tickers_list'\n",
    "\n",
    "print('Tickers list')\n",
    "print(tickers_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_list = data_table ['GICS Sector'].tolist()       # Convert 'GICS Sector' into a list() within 'data_table' assigned to 'sectors_list'\n",
    "\n",
    "print('Sectors list')\n",
    "print(sectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = data_table ['Security'].tolist()         # Convert 'Security' into a list() within 'data_table' assigned to 'stocks_list'\n",
    "\n",
    "print('Stocks list')\n",
    "print(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry_list = data_table ['GICS Sub-Industry'].tolist()                     # Convert 'GICS Sub-Industry' into a list() within 'data_table' assigned to 'Industry_list'\n",
    "\n",
    "print('Industry list')\n",
    "print(Industry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_list = data_table ['Headquarters Location'].tolist()                                  # Convert 'Headquarters Location' into a list() within 'data_table' assigned to 'Location_list'\n",
    "\n",
    "print('Headquarters Location list')\n",
    "print(Location_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sp500_columns = pd.DataFrame({\n",
    "    'Ticker': tickers_list,\n",
    "    'Company': company_list,                                                  # Adding my variables ('tickers_list','stocks_list, and 'sectors_list') to a new Dataframe 'Sp500_columns' using pandas & {}\n",
    "    'Sector': sectors_list,\n",
    "    'Industry': Industry_list,\n",
    "    'Location': Location_list,}) \n",
    "\n",
    "print(Sp500_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiting 'Location' Column Into City & State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'Location' column into 'City' and 'State'\n",
    "split_location = Sp500_columns['Location'].str.split(\", \", n=1, expand=True)\n",
    "\n",
    "if len(split_location.columns) == 2:  # Ensure split results in two columns\n",
    "    Sp500_columns[['City', 'State']] = split_location\n",
    "    Sp500_columns = Sp500_columns.drop(columns=['Location'])\n",
    "else:\n",
    "    print(\"Error: Unable to split 'Location' column into 'City' and 'State' properly.\")\n",
    "\n",
    "print(Sp500_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Market Caps From Each Ticker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Fetch data for tickers\n",
    "for ticker in tickers_list:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "\n",
    "        # Extracting information\n",
    "        market_cap = info.get('marketCap', None)\n",
    "        name = info.get('longName', 'N/A')\n",
    "        sector = info.get('sector', 'N/A')\n",
    "\n",
    "         # Append data to list\n",
    "        data.append({\n",
    "                'Ticker': ticker,\n",
    "                'Company': name,\n",
    "                'Sector': sector,\n",
    "                'Market_Cap': market_cap\n",
    "            })\n",
    "       \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "# Create DataFrame from the data\n",
    "SP500 = pd.DataFrame(data)\n",
    "\n",
    "# Sort by market cap\n",
    "SP500_MCS = SP500.sort_values(by='Market_Cap', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_MCS.drop('Company', axis=1, inplace=True)\n",
    "                                                                     # Dropping Unnecessary columns from DataFrame(SP500_MC)\n",
    "SP500_MCS.drop('Sector', axis=1, inplace=True)\n",
    "\n",
    "print(SP500_MCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Market Cap) & Function Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_market_cap(market_cap):\n",
    "    if isinstance(market_cap, (int, float)):\n",
    "                                                                   # If it's already a numeric value, format it accordingly\n",
    "        if market_cap >= 1e12:\n",
    "            return \"${:.2f} T\".format(market_cap / 1e12)\n",
    "        elif market_cap >= 1e9:\n",
    "            return \"${:.2f} B\".format(market_cap / 1e9)\n",
    "        elif market_cap >= 1e6:\n",
    "            return \"${:.2f} M\".format(market_cap / 1e6)\n",
    "        else:\n",
    "            return \"${:.2f}\".format(market_cap)\n",
    "    else:\n",
    "        try:\n",
    "                                                                   # Convert the market cap value to a floating-point number\n",
    "            market_cap = float(market_cap.replace('$', '').replace('B', 'e9').replace('M', 'e6').replace('T', 'e12'))\n",
    "\n",
    "                                                                   # Check the magnitude of the market cap and append 'T', 'B', or 'M' accordingly\n",
    "            if market_cap >= 1e12:\n",
    "                return \"${:.2f} T\".format(market_cap / 1e12)\n",
    "            elif market_cap >= 1e9:\n",
    "                return \"${:.2f} B\".format(market_cap / 1e9)\n",
    "            elif market_cap >= 1e6:\n",
    "                return \"${:.2f} M\".format(market_cap / 1e6)\n",
    "            else:\n",
    "                return \"${:.2f}\".format(market_cap)\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error formatting market cap: {e}\")\n",
    "            return market_cap                                       # Return the original value if there's an issue with formatting\n",
    "\n",
    "\n",
    "SP500_MCS['Market_Cap'] = SP500_MCS['Market_Cap'].apply(format_market_cap)\n",
    "\n",
    "print(SP500_MCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap_mapping = {\n",
    "'DAY': '$10.69 B',}\n",
    "\n",
    "for ticker, market_cap_value in market_cap_mapping.items():                                                                 \n",
    "   SP500_MCS.loc[SP500_MCS['Ticker'] == ticker, 'Market_Cap'] = market_cap_value \n",
    "\n",
    "print(SP500_MCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Merging (JOIN) Drop And Inserting Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns = pd.merge(Sp500_columns, SP500_MCS[['Ticker', 'Market_Cap']], left_on='Ticker', right_on='Ticker', how='right')             # pd.merge is used to merge two DataFrames 'JOIN'\n",
    "\n",
    "                                                                                   \n",
    "Updated_Sp500_columns.drop('Industry', axis=1, inplace=True)                                                                                        # Dropping Unnecessary Columns in merged DataFrames\n",
    "\n",
    "\n",
    "Updated_Sp500_columns.insert(0, 'Rank', range(1, len(Updated_Sp500_columns) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Realtime Data & Function Creation (Date, Open, Close  & Weekly Volume) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(ticker, period=\"1y\", interval=\"1d\"):\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, period=period, interval=interval)\n",
    "        return stock_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_Date_weekly(stock_data):\n",
    "    if not isinstance(stock_data.index, pd.DatetimeIndex):\n",
    "        raise KeyError(\"DatetimeIndex not found in data.\")\n",
    "\n",
    "    # Resample the data to weekly frequency, considering Friday as the end of the week\n",
    "    Weekly_Date = stock_data.resample('W-Fri').last()\n",
    "\n",
    "    most_recent_weekly_date = Weekly_Date.index[-1]\n",
    "    date_part = most_recent_weekly_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    return date_part\n",
    "\n",
    "def calculate_open_weekly_average(stock_data):\n",
    "    Open_SP500 = stock_data['Open'].resample('W-Fri').last()\n",
    "    most_recent_weekly_open = Open_SP500.iloc[-1]\n",
    "    return most_recent_weekly_open\n",
    "\n",
    "def calculate_close_weekly_average(stock_data):\n",
    "    Close_SP500 = stock_data['Close'].resample('W-Fri').last()\n",
    "    most_recent_weekly_close = Close_SP500.iloc[-1]\n",
    "    return most_recent_weekly_close\n",
    "\n",
    "\n",
    "def calculate_volume_weekly_average(ticker_weekly_data):                                                                               # Defines a function to calculate the weekly average\n",
    "    weekly_average = ticker_weekly_data['Volume'].resample('W-Fri').last()                                                    # Calculates the mean of the weekly average volumes for each ticker\n",
    "    \n",
    "    most_recent_weekly_volume = weekly_average.iloc[-1]                                                                        # Get the most recent weekly open value\n",
    "    return most_recent_weekly_volume  \n",
    "\n",
    "\n",
    "# Apply calculations to each row in the DataFrame\n",
    "Updated_Sp500_columns['Date'] = Updated_Sp500_columns['Ticker'].apply(\n",
    "    lambda ticker: calculate_Date_weekly(download_stock_data(ticker))\n",
    ")\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Ticker'].apply(\n",
    "    lambda ticker: calculate_open_weekly_average(download_stock_data(ticker))\n",
    ")\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Ticker'].apply(\n",
    "    lambda ticker: calculate_close_weekly_average(download_stock_data(ticker))\n",
    ")\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Ticker'].apply(\n",
    "    lambda ticker: calculate_volume_weekly_average(download_stock_data(ticker))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Creation Weekly Percentage (Open/Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns['Weekly_Percentage'] = (((Updated_Sp500_columns['Weekly_Close'] - Updated_Sp500_columns['Weekly_Open']) / Updated_Sp500_columns['Weekly_Open']) * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reapplying Column (Weekly Volume) to the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weekly_Volume = Updated_Sp500_columns.pop('Weekly_Volume')\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Volume'] = Weekly_Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting (Open, Close & Volume) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Average Weekly Open' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Weekly_Open'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Average Weekly Close' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Weekly_Close'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')                                                                                # Using 'locale' to  formatting the 'Weekly Average Volume' column in a DataFrame by adding commas as thousand separators to make it more readable.\n",
    "\n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Weekly_Volume'].apply(lambda x: locale.format_string(\"%d\", x, grouping=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Data Types (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns['Weekly_Open'] = Updated_Sp500_columns['Weekly_Open'].astype(int)                   \n",
    "\n",
    "Updated_Sp500_columns['Weekly_Close'] = Updated_Sp500_columns['Weekly_Close'].astype(int)                    # Converting Columns To int()\n",
    " \n",
    "Updated_Sp500_columns['Weekly_Volume'] = Updated_Sp500_columns['Weekly_Volume'].astype(int)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Historical Data Function Creation (Date, Open, Close, Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_historical_data(ticker):\n",
    "    stock_data = download_stock_data(ticker)\n",
    "    \n",
    "    if stock_data is not None:\n",
    "        historical_data = stock_data.reset_index()[['Date', 'Open', 'Close', 'Volume']]\n",
    "        # Convert 'Date' to datetime format and keep only the date part\n",
    "        historical_data['Date'] = pd.to_datetime(historical_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "        return historical_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a list to store DataFrames for each stock\n",
    "all_historical_data = []\n",
    "\n",
    "# Create a list of tickers from Updated_Sp500_columns DataFrame \n",
    "SP_ticker_list = Updated_Sp500_columns['Ticker'].tolist()\n",
    "\n",
    "# Iterate through each ticker and collect historical data\n",
    "for ticker in SP_ticker_list:\n",
    "    historical_data = collect_historical_data(ticker)\n",
    "    if historical_data is not None:\n",
    "        # Add the ticker and sector as columns for identification\n",
    "        historical_data['Ticker'] = ticker\n",
    "        historical_data['Sector'] = Updated_Sp500_columns.loc[\n",
    "            Updated_Sp500_columns['Ticker'] == ticker, 'Sector'\n",
    "        ].values[0]\n",
    "        all_historical_data.append(historical_data)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "historical_data_df = pd.concat(all_historical_data, ignore_index=True)\n",
    "\n",
    "# Merge with the original Updated_Sp500_columns DataFrame on the 'Ticker' column\n",
    "SP500_Historical_Data = pd.merge(Updated_Sp500_columns, historical_data_df, on='Ticker', how='left')\n",
    "\n",
    "# Drop unnecessary columns in one call\n",
    "columns_to_drop = ['City','State','Date_x', 'Weekly_Open', 'Weekly_Close', 'Weekly_Volume',\n",
    "                    'Market_Cap', 'Sector_y', 'Weekly_Percentage']\n",
    "SP500_Historical_Data = SP500_Historical_Data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Rename columns\n",
    "SP500_Historical_Data = SP500_Historical_Data.rename(columns={'Date_y': 'Date', 'Sector_x': 'Sector'})\n",
    "\n",
    "# Round multiple columns\n",
    "columns_to_round = ['Open', 'Close']\n",
    "SP500_Historical_Data = SP500_Historical_Data.round({col: 2 for col in columns_to_round})\n",
    "\n",
    "# Calculate Percentage Difference\n",
    "SP500_Historical_Data['Percentage_Difference'] = (\n",
    "    ((SP500_Historical_Data['Close'] - SP500_Historical_Data['Open']) / SP500_Historical_Data['Open']) * 100\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reapplying Column (Volume) to the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume = SP500_Historical_Data.pop('Volume')\n",
    "SP500_Historical_Data['Volume'] = Volume\n",
    "\n",
    "print(\"Resulting S&P 500 Historical DataFrame:\")\n",
    "\n",
    "SP500_Historical_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reapplying Column (Market Cap) to the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_Cap = Updated_Sp500_columns.pop('Market_Cap')\n",
    "Updated_Sp500_columns['Market_Cap'] = Market_Cap\n",
    "\n",
    "print(\"Resulting S&P 500 Realtime DataFrame:\")\n",
    "\n",
    "Updated_Sp500_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_Historical_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_Sp500_columns.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrames to Tableau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realtime Data CSV\n",
    "Tableau_path = '/Users/Phases/Desktop/Project XV/Tableau/Tableau_Realtime.csv'\n",
    "\n",
    "Updated_Sp500_columns.to_csv(Tableau_path, index=False)\n",
    "\n",
    "# Historical Data CSV\n",
    "Tableau_Historical_path = '/Users/Phases/Desktop/Project XV/Tableau/Tableau_Historical.csv'\n",
    "\n",
    "SP500_Historical_Data.to_csv(Tableau_Historical_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/Phases/Desktop/Project XV/Excel'\n",
    "file_name = 'SP500_Realtime_Excel.xlsx'\n",
    "\n",
    "# Get the full path to the Excel file\n",
    "excel_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Make sure the folder exists, create it if not\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to Excel\n",
    "Updated_Sp500_columns.to_excel(excel_file_path, index=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame To SQLite With Primary Key (Realtime Data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/Users/Phases/Desktop/Project XV'\n",
    "instance_folder = 'Instance'\n",
    "SP_Database = 'SP500_Database.db'\n",
    "SP500_Database_Path = os.path.join(project_path, instance_folder, SP_Database)\n",
    "\n",
    "# Connect to the SQLite database using the new file path\n",
    "conn = sqlite3.connect(SP500_Database_Path)\n",
    "\n",
    "Updated_Sp500_columns.to_sql('SP500_Realtime_Data', conn, index=False, if_exists='replace')   # Adding DataFrame To SQLite Database\n",
    "\n",
    "cursor = conn.cursor()    # Starting SQL Query \n",
    "\n",
    "                          # Creating New Table With Primary Key (Realtime Data)\n",
    "cursor.execute('''         \n",
    "    CREATE TABLE IF NOT EXISTS SP500_Columns_Key_New (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        Rank INTEGER,\n",
    "        Ticker TEXT,\n",
    "        Company TEXT,\n",
    "        Sector TEXT,\n",
    "        City TEXT,\n",
    "        State TEXT,\n",
    "        Date DATE,\n",
    "        Weekly_Open REAL,\n",
    "        Weekly_Close REAL,\n",
    "        Weekly_Percentage TEXT,\n",
    "        Weekly_Volume INTEGER,\n",
    "        Market_Cap TEXT\n",
    "    )''')\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                          # Copying Data From Existing Table To The New Table With Primary Key\n",
    "cursor.execute('''\n",
    "    INSERT INTO SP500_Columns_Key_New (Rank, Ticker, Company, Sector, City, State, Date, Weekly_Open, Weekly_Close, Weekly_Percentage, Weekly_Volume, Market_Cap)    \n",
    "    SELECT Rank, Ticker, Company, Sector, City, State, Date, Weekly_Open, Weekly_Close, Weekly_Percentage, Weekly_Volume, Market_Cap\n",
    "    FROM SP500_Realtime_Data\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                         # Renaming Both Tables One With Primary Key and One Without\n",
    "cursor.execute('''\n",
    "    ALTER TABLE SP500_Realtime_Data RENAME TO SP500_Columns_Key_Old\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    ALTER TABLE SP500_Columns_Key_New RENAME TO SP500_Realtime_Data\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "                        # Dropping Old Table \n",
    "cursor.execute('''\n",
    "    DROP TABLE IF EXISTS SP500_Columns_Key_Old\n",
    "''')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting DataFrame To SQLite With Primary Key (Historical Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database using the new file path\n",
    "conn = sqlite3.connect(SP500_Database_Path)\n",
    "\n",
    "# Adding DataFrame to SQLite Database\n",
    "SP500_Historical_Data.to_sql('SP500_Historical_Data', conn, index=False, if_exists='replace')\n",
    "\n",
    "cursor = conn.cursor()    # Starting SQL Query\n",
    "\n",
    "# Creating a new table (Historical Data)\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS SP500_Historical_Data (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        Rank INTEGER,\n",
    "        Ticker TEXT,\n",
    "        Company TEXT,\n",
    "        Sector TEXT,\n",
    "        Date DATE,\n",
    "        Open REAL,\n",
    "        Close REAL,\n",
    "        Percentage_Difference TEXT,\n",
    "        Volume INTEGER\n",
    "    )''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Copying data from the existing table to the new table with a primary key\n",
    "cursor.execute('''\n",
    "    INSERT INTO SP500_Historical_Data (Rank, Ticker, Company, Sector, Date, Open, Close, Percentage_Difference, Volume)    \n",
    "    SELECT Rank, Ticker, Company, Sector, Date, Open, Close, Percentage_Difference, Volume\n",
    "    FROM SP500_Historical_Data\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
